{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961fbc26-c740-493f-8bee-b0d20516a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "module_path = '../'\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from detectors import BlackBoxInfluenceFunctionDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0586c6d-ac68-4790-8c34-40a0fdfa2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"SMAP_MSL\"\n",
    "data_path = Path(\"../../data/multivariate/\") / dataset\n",
    "test_df = pd.read_csv(data_path/\"labeled_anomalies.csv\")\n",
    "smap_df = test_df.loc[test_df.spacecraft == \"SMAP\"]\n",
    "# remove P-2 since anomaly transformer also removes this channel\n",
    "df = smap_df.loc[smap_df.chan_id != \"P-2\"]\n",
    "# msl_df = test_df.loc[test_df.spacecraft == \"MSL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "255bcfb6-28be-4aef-9f07-966999416fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.win_size = 25\n",
    "        self.data_path = './data_processed/SMAP'\n",
    "        self.dimensions = [0]\n",
    "        self.dataset = 'SMAP'\n",
    "        self.verbose = False\n",
    "        self.black_box_model = \"LSTM\"\n",
    "        self.device = \"cpu\"\n",
    "        self.lr = 1e-3\n",
    "        self.num_epochs = 100\n",
    "        self.weight_decay = 1e-4\n",
    "        self.batch_size = 32\n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = 16\n",
    "\n",
    "df = smap_df.loc[smap_df.chan_id != \"P-2\"]\n",
    "config = Config()\n",
    "detector = BlackBoxInfluenceFunctionDetector(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975dc1be-91b0-4cee-b618-9d444af8057d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly ratio is 8.795 %.\n",
      "start detection for channel P-1 ..\n",
      "block length is 25 time points.\n",
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizizhang/Desktop/time-series-influence/anomaly_detection/notebooks/../detectors.py:341: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  return torch.tensor(X).to(device), torch.tensor(Y).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train RMSE 0.2236\n",
      "Epoch 1: train RMSE 0.1990\n",
      "Epoch 2: train RMSE 0.1958\n",
      "Epoch 3: train RMSE 0.1940\n",
      "Epoch 4: train RMSE 0.1929\n",
      "Epoch 5: train RMSE 0.1915\n",
      "Epoch 6: train RMSE 0.1900\n",
      "Epoch 7: train RMSE 0.1888\n",
      "Epoch 8: train RMSE 0.1874\n",
      "Epoch 9: train RMSE 0.1861\n",
      "Epoch 10: train RMSE 0.1852\n",
      "Epoch 11: train RMSE 0.1841\n",
      "Epoch 12: train RMSE 0.1832\n",
      "Epoch 13: train RMSE 0.1827\n",
      "Epoch 14: train RMSE 0.1823\n",
      "Epoch 15: train RMSE 0.1817\n",
      "Epoch 16: train RMSE 0.1811\n",
      "Epoch 17: train RMSE 0.1805\n",
      "Epoch 18: train RMSE 0.1803\n",
      "Epoch 19: train RMSE 0.1799\n",
      "Epoch 20: train RMSE 0.1799\n",
      "Epoch 21: train RMSE 0.1800\n",
      "Epoch 22: train RMSE 0.1803\n",
      "Epoch 23: train RMSE 0.1793\n",
      "Epoch 24: train RMSE 0.1791\n",
      "Epoch 25: train RMSE 0.1791\n",
      "Epoch 26: train RMSE 0.1789\n",
      "Epoch 27: train RMSE 0.1790\n",
      "Epoch 28: train RMSE 0.1789\n",
      "Epoch 29: train RMSE 0.1786\n",
      "Epoch 30: train RMSE 0.1791\n",
      "Epoch 31: train RMSE 0.1787\n",
      "Epoch 32: train RMSE 0.1785\n",
      "Epoch 33: train RMSE 0.1787\n",
      "Epoch 34: train RMSE 0.1780\n",
      "Epoch 35: train RMSE 0.1778\n",
      "Epoch 36: train RMSE 0.1778\n",
      "Epoch 37: train RMSE 0.1775\n",
      "Epoch 38: train RMSE 0.1773\n",
      "Epoch 39: train RMSE 0.1771\n",
      "Epoch 40: train RMSE 0.1771\n",
      "Epoch 41: train RMSE 0.1767\n",
      "Epoch 42: train RMSE 0.1770\n",
      "Epoch 43: train RMSE 0.1766\n",
      "Epoch 44: train RMSE 0.1763\n",
      "Epoch 45: train RMSE 0.1762\n",
      "Epoch 46: train RMSE 0.1767\n",
      "Epoch 47: train RMSE 0.1763\n",
      "Epoch 48: train RMSE 0.1761\n",
      "Epoch 49: train RMSE 0.1761\n",
      "Epoch 50: train RMSE 0.1759\n",
      "Epoch 51: train RMSE 0.1759\n",
      "Epoch 52: train RMSE 0.1759\n",
      "Epoch 53: train RMSE 0.1757\n",
      "Epoch 54: train RMSE 0.1755\n",
      "Epoch 55: train RMSE 0.1755\n",
      "Epoch 56: train RMSE 0.1754\n",
      "Epoch 57: train RMSE 0.1771\n",
      "Epoch 58: train RMSE 0.1754\n",
      "Epoch 59: train RMSE 0.1756\n",
      "Epoch 60: train RMSE 0.1751\n",
      "Epoch 61: train RMSE 0.1750\n",
      "Epoch 62: train RMSE 0.1750\n",
      "Epoch 63: train RMSE 0.1749\n",
      "Epoch 64: train RMSE 0.1756\n",
      "Epoch 65: train RMSE 0.1753\n",
      "Epoch 66: train RMSE 0.1750\n",
      "Epoch 67: train RMSE 0.1747\n",
      "Epoch 68: train RMSE 0.1749\n",
      "Epoch 69: train RMSE 0.1748\n",
      "Epoch 70: train RMSE 0.1750\n",
      "Epoch 71: train RMSE 0.1745\n",
      "Epoch 72: train RMSE 0.1753\n",
      "Epoch 73: train RMSE 0.1745\n",
      "Epoch 74: train RMSE 0.1746\n",
      "Epoch 75: train RMSE 0.1743\n",
      "Epoch 76: train RMSE 0.1745\n",
      "Epoch 77: train RMSE 0.1744\n",
      "Epoch 78: train RMSE 0.1743\n",
      "Epoch 79: train RMSE 0.1741\n",
      "Epoch 80: train RMSE 0.1742\n",
      "Epoch 81: train RMSE 0.1742\n",
      "Epoch 82: train RMSE 0.1743\n",
      "Epoch 83: train RMSE 0.1743\n",
      "Epoch 84: train RMSE 0.1742\n",
      "Epoch 85: train RMSE 0.1739\n",
      "Epoch 86: train RMSE 0.1739\n",
      "Epoch 87: train RMSE 0.1738\n",
      "Epoch 88: train RMSE 0.1739\n",
      "Epoch 89: train RMSE 0.1741\n",
      "Epoch 90: train RMSE 0.1739\n",
      "Epoch 91: train RMSE 0.1738\n",
      "Epoch 92: train RMSE 0.1740\n",
      "Epoch 93: train RMSE 0.1737\n",
      "Epoch 94: train RMSE 0.1736\n",
      "Epoch 95: train RMSE 0.1742\n",
      "Epoch 96: train RMSE 0.1739\n",
      "Epoch 97: train RMSE 0.1741\n",
      "Epoch 98: train RMSE 0.1740\n",
      "Epoch 99: train RMSE 0.1741\n"
     ]
    }
   ],
   "source": [
    "len_test_dict, len_anomaly_dict, len_ratio_dict = {}, {}, {}\n",
    "prec_dict, rec_dict, f1_dict, auc_dict, best_f1_dict = {}, {}, {}, {}, {}\n",
    "prec_adj_dict, rec_adj_dict, f1_adj_dict = {}, {}, {}\n",
    "time_dict = {}\n",
    "\n",
    "for channel in df.chan_id:\n",
    "\n",
    "    if config.dimensions is not None:\n",
    "        ts_test = np.load(data_path/\"test\"/f\"{channel}.npy\")[:,config.dimensions]\n",
    "    else:\n",
    "        ts_test = np.load(data_path/\"test\"/f\"{channel}.npy\")\n",
    "\n",
    "    # import ipdb\n",
    "    # ipdb.set_trace()\n",
    "\n",
    "    seq_len = len(ts_test)\n",
    "    anomaly_seqs = df.loc[df.chan_id == channel].anomaly_sequences.to_numpy().item()\n",
    "    anomaly_seqs = re.findall(r'\\d+', anomaly_seqs)\n",
    "    anomaly_intervals = []\n",
    "    for i in list(range(0, len(anomaly_seqs), 2)):\n",
    "        anomaly_intervals.append(anomaly_seqs[i:i+2])\n",
    "    anomaly_intervals = np.array(anomaly_intervals).astype(int)\n",
    "\n",
    "    ground_truth = np.zeros(ts_test.shape[0])\n",
    "    plt.figure(figsize=(16,1))\n",
    "    plt.plot(ts_test, c=\"k\", linewidth=.5)\n",
    "    for anomaly_points in anomaly_intervals:\n",
    "        plt.axvspan(anomaly_points[0], anomaly_points[-1], facecolor='red', alpha=.2)\n",
    "        ground_truth[anomaly_points[0]:anomaly_points[-1]] = 1.\n",
    "\n",
    "    anomaly_len = sum(ground_truth)\n",
    "    anomaly_ratio = anomaly_len / seq_len\n",
    "    print(f\"anomaly ratio is {anomaly_ratio * 100.:.3f} %.\")\n",
    "\n",
    "    len_test_dict.update({channel: seq_len})\n",
    "    len_anomaly_dict.update({channel: anomaly_len})\n",
    "    len_ratio_dict.update({channel: anomaly_ratio})\n",
    "\n",
    "    print(f\"start detection for channel {channel} ..\")\n",
    "    start_time = time.time()\n",
    "    anomaly_scores = detector.calculate_anomaly_scores(ts = ts_test, channel_id = channel, contamination = min(anomaly_ratio,0.5)) # contamination has to be inthe range (0.0,0.5]\n",
    "    end_time = time.time()\n",
    "    elapsed_time = round(end_time - start_time, 3)\n",
    "    \n",
    "    plt.figure(figsize=(16,1))\n",
    "    loos_viz = np.ones(len(ts_test)) * np.nan\n",
    "    loos_viz[:len(anomaly_scores)] = anomaly_scores\n",
    "    plt.plot(loos_viz, c=\"k\", linewidth=.5)\n",
    "    for anomaly_points in anomaly_intervals:\n",
    "        plt.axvspan(anomaly_points[0], anomaly_points[-1], facecolor='red', alpha=.2)\n",
    "        ground_truth[anomaly_points[0]:anomaly_points[-1]] = 1.\n",
    "    plt.ylabel(\"anomaly score\")\n",
    "    plt.show()\n",
    "    \n",
    "    detected_outliers = anomaly_scores > np.quantile(anomaly_scores, 1-anomaly_ratio) #\n",
    "    plt.figure(figsize=(16,1))\n",
    "    loos_viz = np.ones(len(ts_test)) * np.nan\n",
    "    loos_viz[:len(detected_outliers)] = detected_outliers\n",
    "    plt.plot(loos_viz, c=\"k\", linewidth=.5)\n",
    "    for anomaly_points in anomaly_intervals:\n",
    "        plt.axvspan(anomaly_points[0], anomaly_points[-1], facecolor='red', alpha=.2)\n",
    "        ground_truth[anomaly_points[0]:anomaly_points[-1]] = 1.\n",
    "    plt.ylabel(\"is outlier?\")\n",
    "    plt.show()\n",
    "    \n",
    "    prec, rec, f1, auc, prec_adj, rec_adj, f1_adj,  best_f1 = detector.evaluate(ground_truth, anomaly_scores, anomaly_ratio)\n",
    "\n",
    "    prec_dict.update({channel: prec})\n",
    "    rec_dict.update({channel: rec})\n",
    "    f1_dict.update({channel: f1})\n",
    "    auc_dict.update({channel: auc})\n",
    "    best_f1_dict.update({channel: best_f1})\n",
    "\n",
    "    time_dict.update({channel: elapsed_time})\n",
    "\n",
    "    prec_adj_dict.update({channel: prec_adj})\n",
    "    rec_adj_dict.update({channel: rec_adj})\n",
    "    f1_adj_dict.update({channel: f1_adj})\n",
    "\n",
    "    break # remove this!\n",
    "\n",
    "smap_metrics = pd.DataFrame({\n",
    "    \"Num_of_Test\": len_test_dict,\n",
    "    \"Len_of_Anomaly\": len_anomaly_dict,\n",
    "    \"Anomaly_Ratio\": len_ratio_dict,\n",
    "    \"Precision(w.o. Adjustment)\": prec_dict,\n",
    "    \"Recall(w.o. Adjustment)\": rec_dict,\n",
    "    \"F1(w.o. Adjustment)\": f1_dict,\n",
    "    \"Precision(w. Adjustment)\": prec_adj_dict,\n",
    "    \"Recall(w. Adjustment)\": rec_adj_dict,\n",
    "    \"F1(w. Adjustment)\": f1_adj_dict,\n",
    "    \"Best_F1_Score\": best_f1_dict,\n",
    "    \"AUC\": auc_dict,\n",
    "    'Detection_Time(s)': time_dict\n",
    "})\n",
    "\n",
    "smap_metrics.insert(0, \"Dataset\", smap_metrics.index)\n",
    "smap_metrics.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e860d9-b7c3-49b7-80f0-d37fe600aee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef6163-9be2-4c7a-ab18-d5ed9bee7487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4731503-1acd-45e7-8930-3b8b23bd7447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96378b49-8091-47c2-9f0d-4318e2638da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
